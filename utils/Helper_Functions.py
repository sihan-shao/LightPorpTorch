import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import copy

def total_variation(input: torch.tensor):
    '''
    compute centerered finite difference derivative for input along dimensions dim
    zero pad the boundary

    input: 4D torch tensor with dimension 2,3 being the spatial difference
    returns: scalar value |dx|_1 + |dy|_1  
    '''
    # reshape if its a 6D tensor
    if input.ndim == 6:
        B,T,P,C,H,W = input.shape
        input = input.view(B*T*P,C,H,W)

    dx, dy = center_difference(input)
    return dx.abs().mean() + dy.abs().mean()

def center_difference(input: torch.tensor):
    '''
    compute centerered finite difference derivative for input along dimensions dim
    zero pad the boundary

    input: 4D torch tensor with dimension 2,3 being the spatial difference
    returns: dx, dy - 4D tensors same size as input 
    '''
    # create a new tensor of zeros for zeropadding
    dx = torch.zeros_like(input)
    dy = torch.zeros_like(input)
    _, _, H, W = input.shape
    dx[:,:,:,1:-1] = W/4*(-input[:,:,:,0:-2] + 2*input[:,:,:,1:-1] - input[:,:,:,2:])
    dy[:,:,1:-1,:] = H/4*(-input[:,:,0:-2,:] + 2*input[:,:,1:-1,:] - input[:,:,2:,:])
    return dx, dy

def wrap_phase(phase_u: torch.Tensor, stay_positive: bool = False) -> torch.Tensor:
    """Wrap phase values to [-π, π] or [0, 2π] range.

    Args:
        phase_u (torch.Tensor): Unwrapped phase values tensor
        stay_positive (bool): If True, output range is [0, 2π]. If False, [-π, π]

    Returns:
        torch.Tensor: Wrapped phase values tensor

    Examples:
        >>> phase = torch.tensor([3.5 * np.pi, -2.5 * np.pi])
        >>> wrapped = wrap_phase(phase)  # tensor([0.5000 * π, -0.5000 * π])
    """
    phase = phase_u % (2 * np.pi)
    if not stay_positive:
        phase[phase > torch.pi] -= 2 * np.pi
    return phase

def ft2(input, delta=1, norm = 'ortho', pad = False):
    """
    Helper function computes a shifted fourier transform with optional scaling
    """
    return perform_ft(
        input=input,
        delta = delta,
        norm = norm,
        pad = pad,
        flag_ifft=False
    )

def ift2(input, delta=1, norm = 'ortho', pad = False):
    
    return perform_ft(
        input=input,
        delta = delta,
        norm = norm,
        pad = pad,
        flag_ifft=True
    )

def perform_ft(input, delta=1, norm = 'ortho', pad = False, flag_ifft : bool = False):
    
    # Get the initial shape (used later for transforming 6D to 4D)
    tmp_shape = input.shape

    # Save Size for later crop
    Nx_old = int(input.shape[-2])
    Ny_old = int(input.shape[-1])
        
    # Pad the image for avoiding convolution artifacts
    if pad == True:
        
        pad_scale = 1
        
        pad_nx = int(pad_scale * Nx_old / 2)
        pad_ny = int(pad_scale * Ny_old / 2)
        
        input = torch.nn.functional.pad(input, (pad_ny,pad_ny,pad_nx,pad_nx), mode='constant', value=0)
    
    if flag_ifft == False:
        myfft = torch.fft.fft2
        my_fftshift = torch.fft.fftshift
    else:
        myfft = torch.fft.ifft2
        my_fftshift = torch.fft.ifftshift


    
    # Compute the Fourier Transform
    out = (delta**2)* my_fftshift( myfft (  my_fftshift (input, dim=(-2,-1))  , dim=(-2,-1), norm=norm)  , dim=(-2,-1))
    
    if pad == True:
        input_size = [Nx_old, Ny_old]
        pool = torch.nn.AdaptiveAvgPool2d(input_size)
        
        if out.is_complex():
            out = pool(out.real) + 1j * pool(out.imag)
        else:
            out = pool(out)
    return out


def normalize(x):
    """normalize to range [0-1]"""
    batch_size, num_obj, height, width = x.shape

    x = x.view(batch_size, -1)
    # x -= x.min(1, keepdim=True)[0]
    x /= x.max(1, keepdim=True)[0]
    x = x.view(batch_size, num_obj, height, width)
    return x

def DOE_xyz_cordinates_Generator(height_map, dxy, new_dxy=0.001 ,origin='center', interp='nearest', for_matlab=True):
    import numpy as np
    import cv2
    import pandas as pd
    from datetime import datetime
    """

    The XYZ coordinates generated by the height map are used to build a 3D CAD model for 3D printing. 
    Here, we use them with CST API in MATLAB to generate a CAD (.stl) model on CST software.

    Param:
    height_map_path: the path of 2D height map (z-coordinate) of designed hologram.
    dxy: the physcial interval of the hologram
    new_dxy: the new physical interval after upsampling to satisfy the requirement
    origin: the origin point (0, 0, z) of x- adn y- coordinate. options: center, left-up, left-bottom
    for_matlab: if True, use C order to Flatten the 2D array. More details see: https://numpy.org/doc/stable/user/numpy-for-matlab-users.html [RESHAPE and LINEAR INDEXING]
    
    Return: 
    csv file with shape [N, 3], with N = Nx * Ny, and columns are x-, y-, and z-coordinates.
    """
    #height_map = np.load(height_map_path)
    height, width = height_map.shape
    physcial_length = height * dxy
    print("The physical length of hologram is {} mm".format(physcial_length / 1e-3))
    
    upsampling_height = int(height * round(dxy / new_dxy))
    upsampling_width  = int(width * round(dxy / new_dxy))
    print(upsampling_height)
    # Resize the data
    if interp == 'nearest':
        resized_height_map = cv2.resize(height_map, (upsampling_width, upsampling_height), interpolation=cv2.INTER_NEAREST)
    elif interp == 'linear':
        resized_height_map = cv2.resize(height_map, (upsampling_width, upsampling_height), interpolation=cv2.INTER_LINEAR)
        
        
    # decde the origin and find the x- and y- coordinate based on origin
    if origin == 'center':
        x_coords, y_coords = np.meshgrid(np.linspace(-upsampling_width / 2 * new_dxy, upsampling_width / 2 * new_dxy, upsampling_width),
                                         np.linspace(-upsampling_height / 2 * new_dxy, upsampling_height / 2 * new_dxy, upsampling_height))
    elif origin == 'left-up':
        x_coords, y_coords = np.meshgrid(np.linspace(0, upsampling_width * new_dxy, upsampling_width),
                                         np.linspace(0, upsampling_height * new_dxy, upsampling_height))

    
    # Flatten the coordinates and height map
    x_flat = x_coords.flatten()
    y_flat = y_coords.flatten()
    if for_matlab:
        z_flat = resized_height_map.T.flatten(order='C')
    else:
        z_flat = resized_height_map.T.flatten()

    coordinates_xyz = np.stack([x_flat, y_flat, z_flat], axis=-1).reshape(-1, 3)
    
    date = datetime.now()

    np.savetxt(f"DOE_xyz_coordinates_{date.strftime('%Y%m%d-%H%M%S')}.csv", coordinates_xyz, delimiter=",")


    def calculate_psnr(img1: torch.Tensor, img2: torch.Tensor, data_range: Optional[float] = 1.0) -> float:
    """Calculate Peak Signal-to-Noise Ratio between multi-channel tensors.

    Args:
        img1 (torch.Tensor): First tensor [B, Channel, R, C]
        img2 (torch.Tensor): Second tensor [B, Channel, R, C]
        data_range (float, optional): The data range of the input image (e.g., 1.0 for normalized images, 
                            255 for uint8 images). If None, uses the maximum value from images.

    Returns:
        float: PSNR value in dB, infinity if images are identical

    Examples:
        >>> intensity1 = light1.get_intensity()  # [B, Channel, R, C]
        >>> intensity2 = light2.get_intensity()  # [B, Channel, R, C]
        >>> psnr = calculate_psnr(intensity1, intensity2)
    """
    if img1.shape != img2.shape:
        raise ValueError("Input tensors must have the same shape")
        
    img2 = img2.to(img1.device)
    
    # If data_range is None, determine it from the input images
    if data_range is None:
        data_range = max(torch.max(img1).item(), torch.max(img2).item())
    
    # If tensor is 4D [B, C, H, W], compute MSE per batch and channel, then average
    if len(img1.shape) == 4:
        mse = torch.mean((img1 - img2) ** 2, dim=(-1, -2))  # MSE per batch and channel
        mse = torch.mean(mse)  # Average over batches and channels
    else:
        mse = torch.mean((img1 - img2) ** 2)
    
    if mse == 0:
        return float('inf')
    
    epsilon = 1e-10

    return 20 * torch.log10(data_range / torch.sqrt(mse + epsilon))

def calculate_ssim(img1: torch.Tensor, img2: torch.Tensor, 
                  window_size: int = 21, 
                  sigma: Optional[float] = None, 
                  data_range: float = 1.0) -> float:
    """Calculate Structural Similarity Index between multi-channel tensors.

    Args:
        img1 (torch.Tensor): First tensor [B, Channel, H, W]
        img2 (torch.Tensor): Second tensor [B, Channel, H, W]
        window_size (int): Size of Gaussian window (odd number)
        sigma (float, optional): Standard deviation of Gaussian window. 
                               If None, defaults to window_size/6
        data_range (float): Dynamic range of images

    Returns:
        float: SSIM score (-1 to 1, where 1 indicates identical images)

    Examples:
        >>> intensity1 = light1.get_intensity()  # [B, Channel, R, C]
        >>> intensity2 = light2.get_intensity()  # [B, Channel, R, C]
        >>> similarity = calculate_ssim(intensity1, intensity2)
    """
    if sigma is None:
        sigma = window_size / 6

    if img1.shape != img2.shape:
        raise ValueError('Input images must have the same dimensions.')
    
    img2 = img2.to(img1.device)
    window = gaussian_window(window_size, sigma).to(img1.device)
    window = window.unsqueeze(0).unsqueeze(0)
    
    # Constants for numerical stability
    C1 = (0.01 * data_range) ** 2
    C2 = (0.03 * data_range) ** 2

    # Compute means (window will be automatically broadcasted across batch and channels)
    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=img1.size(1))
    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=img2.size(1))
    
    mu1_sq = mu1 ** 2
    mu2_sq = mu2 ** 2
    mu1_mu2 = mu1 * mu2

    # Compute variances and covariance
    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size//2, groups=img1.size(1)) - mu1_sq
    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size//2, groups=img2.size(1)) - mu2_sq
    sigma12 = F.conv2d(img1 * img2, window, padding=window_size//2, groups=img1.size(1)) - mu1_mu2

    # SSIM formula
    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \
               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
    
    return ssim_map.mean()

def gaussian_window(size: int, sigma: float) -> torch.Tensor:
    """Create normalized 2D Gaussian window.

    Args:
        size (int): Width and height of square window
        sigma (float): Standard deviation of Gaussian

    Returns:
        torch.Tensor: Normalized 2D Gaussian window [size, size]

    Examples:
        >>> window = gaussian_window(11, 1.5)
    """
    coords = torch.arange(size, dtype=torch.float32) - size // 2
    grid = torch.meshgrid(coords, coords, indexing='ij')
    window = torch.exp(-(grid[0] ** 2 + grid[1] ** 2) / (2 * sigma ** 2))
    return window / window.sum()